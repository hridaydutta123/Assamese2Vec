{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-45f3883ff7b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mallFiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/'"
     ]
    }
   ],
   "source": [
    "allFiles = os.listdir('output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = []\n",
    "\n",
    "for files in os.listdir('Output/others/'):\n",
    "    with open('Output/others/' + files,'r') as fr:\n",
    "        content.append(fr.read())\n",
    "\n",
    "for files in os.listdir('Output/Kobita/'):\n",
    "    with open('Output/Kobita/' + files,'r') as fr:\n",
    "        content.append(fr.read())\n",
    "        \n",
    "for files in os.listdir('Output/Prabandh/'):\n",
    "    with open('Output/Prabandh/' + files,'r') as fr:\n",
    "        content.append(fr.read())\n",
    "\n",
    "for files in os.listdir('Output/Bhinnasad/'):\n",
    "    with open('Output/Bhinnasad/' + files,'r') as fr:\n",
    "        content.append(fr.read())\n",
    "content = ' '.join(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'১'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def replace_strings(texts, replace):\n",
    "    new_texts=[]\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    english_pattern=re.compile('[a-zA-Z0-9]+', flags=re.I)\n",
    "    \n",
    "    for text in texts:\n",
    "        for r in replace:\n",
    "            text=text.replace(r[0], r[1])\n",
    "        text=emoji_pattern.sub(r'', text)\n",
    "        text=english_pattern.sub(r'', text)\n",
    "        text=re.sub(r'\\s+', ' ', text).strip()\n",
    "        new_texts.append(text)\n",
    "\n",
    "    return new_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(sentences):\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "    new_sentences=[]\n",
    "    exclude = list(set(string.punctuation))\n",
    "    exclude.extend([\"’\", \"‘\", \"—\", \"”\", \"“\"])\n",
    "    for sentence in sentences:\n",
    "        s = ''.join(ch for ch in sentence if ch not in exclude)\n",
    "        new_sentences.append(s)\n",
    "    \n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mCrawled Unprocessed Text\u001b[0m\n",
      "\u001b[31mSentences after removing all punctuations\u001b[0m\n",
      "\u001b[31mSentences after replacing strings\u001b[0m\n",
      "16576\n"
     ]
    }
   ],
   "source": [
    "print(\"\\x1b[31mCrawled Unprocessed Text\\x1b[0m\")\n",
    "\n",
    "replace=[('\\u200c', ' '),\n",
    "         ('\\u200d', ' '),\n",
    "        ('\\xa0', ' '),\n",
    "        ('\\n', ' '),\n",
    "        ('\\r', ' ')]\n",
    "\n",
    "content_split = content.split('|')\n",
    "content_new = remove_punc(content_split)\n",
    "\n",
    "print(\"\\x1b[31mSentences after removing all punctuations\\x1b[0m\")\n",
    "# print(content_new[0:2])\n",
    "\n",
    "content_new = replace_strings(content_new, replace)\n",
    "print(\"\\x1b[31mSentences after replacing strings\\x1b[0m\")\n",
    "# print(content_new[0:2])\n",
    "\n",
    "print(len(content_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198230\n",
      "[['ঘৰ', 'সংসাৰ', '১৮', 'প্ৰদ্যুতজ্যোতি', 'শইকীয়া', 'বেজৰ', 'নাকত', 'খৰ'], ['এই', 'কথাষাৰী', 'প্ৰায়েই', 'আওঁৰাই', 'থাকে', 'আমাৰ', 'গৃহমন্ত্ৰীয়ে'], ['যেতিয়াই', 'ম', 'ই', 'অসুখত', 'ভোগো', 'তেতিয়াই'], ['অসুখ', 'মানেনো', 'কি', 'সাধাৰণ', 'পানীলগা', 'জ্বৰকাঁহ', 'ইত্যাদি', 'ইত্যাদি'], ['প্ৰায়েই', 'অৱজ্ঞাই', 'কৰোঁ'], ['পিছে', 'এইবাৰ', 'ফকৰা', 'যোজনাটি', 'বাৰুকৈয়েই', 'খাটিলে', 'মোৰ', 'লগত'], ['বেজৰ', 'নাকত', 'খৰ'], ['প্ৰথমে', 'গুৰুত্ব', 'ই', 'দিয়া', 'নাছিলো', 'কথাটোত'], ['সেইদিনা', 'ৰাতিপুৱা', 'শুই', 'উঠাৰ', 'সময়ত', 'শ্ৰীমতীয়েহে', 'কলে', 'হেৰি', 'আপোনাৰ', 'দেখোন', 'চকুকেইটা', 'কিবা', 'হালধীয়া', 'হালধীয়া', 'লাগিছে', 'যে।ভেকাহি', 'মাৰি', 'উঠিলো', 'থোৱাহে', 'তোমাৰ', 'কথা'], ['আপদ', 'মাতিছা', 'কিয়', 'যোৱা', 'আদা', 'দি', 'লাল', 'চাহ', 'অকণমান', 'দিয়া']]\n"
     ]
    }
   ],
   "source": [
    "body = content_new\n",
    "body=[article.split('। ') for article in body]\n",
    "body=[item for sublist in body for item in sublist]\n",
    "body=[item.strip() for item in body if len(item.split())>1]\n",
    "\n",
    "body=[item.split() for item in body]\n",
    "print(len(body))\n",
    "print(body[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ঘৰ', 'সংসাৰ', '১৮', 'প্ৰদ্যুতজ্যোতি', 'শইকীয়া', 'বেজৰ', 'নাকত', 'খৰ']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input_data.pickle', 'wb') as handle:\n",
    "    pickle.dump(body, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(body, size=200, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_content.pickle', 'wb') as handle:\n",
    "    pickle.dump(body, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('অসমীয়া', 0.9090224504470825),\n",
       " ('বাংলা', 0.8711240291595459),\n",
       " ('লিপিত', 0.8560170531272888),\n",
       " ('ভাষাৰ', 0.8505398035049438),\n",
       " ('সাহিত্যৰ', 0.8477461934089661)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('অসমীয়া', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9037555"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('লৰা', 'ছোৱালী')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('মা', 0.8765660524368286),\n",
       " ('আইতা', 0.8376446962356567),\n",
       " ('ককা', 0.8301512002944946),\n",
       " ('বাইদেউ', 0.8157236576080322),\n",
       " ('মাজনী', 0.8037220239639282),\n",
       " ('এওঁ', 0.7922283411026001),\n",
       " ('মামা', 0.7899149656295776),\n",
       " ('বৌ', 0.7805209159851074),\n",
       " ('সেইজনী', 0.7703799605369568),\n",
       " ('তোমালোক', 0.7692973017692566)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['দেউতা','ছোৱালী'], negative=['লৰা'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14620541"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('অসমীয়া','গামোচা')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
